{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8aede979-068f-489d-a683-139e58cb6013",
      "metadata": {},
      "source": [
        "# Land cover classification at the Mississppi Delta\n",
        "\n",
        "In this notebook, you will use a k-means **unsupervised** clustering\n",
        "algorithm to group pixels by similar spectral signatures. **k-means** is\n",
        "an **exploratory** method for finding patterns in data. Because it is\n",
        "unsupervised, you don’t need any training data for the model. You also\n",
        "can’t measure how well it “performs” because the clusters will not\n",
        "correspond to any particular land cover class. However, we expect at\n",
        "least some of the clusters to be identifiable as different types of land\n",
        "cover.\n",
        "\n",
        "You will use the [harmonized Sentinel/Landsat multispectral\n",
        "dataset](https://lpdaac.usgs.gov/documents/1698/HLS_User_Guide_V2.pdf).\n",
        "You can access the data with an [Earthdata\n",
        "account](https://www.earthdata.nasa.gov/learn/get-started) and the\n",
        "[`earthaccess` library from\n",
        "NSIDC](https://github.com/nsidc/earthaccess):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396f3173",
      "metadata": {},
      "source": [
        "## STEP 1: Set up\n",
        "\n",
        "### Step 1a: Load libraries and set GDAL parameters\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "<li>Import all libraries you will need for this analysis</li>\n",
        "<li>Configure GDAL parameters to help avoid connection errors:\n",
        "<code>python      os.environ[\"GDAL_HTTP_MAX_RETRY\"] = \"5\"      os.environ[\"GDAL_HTTP_RETRY_DELAY\"] = \"1\"</code></li>\n",
        "</ol></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f0f55c",
      "metadata": {
        "highlight": true
      },
      "outputs": [],
      "source": [
        "# Use \"pip install ____\" in the terminal to install missing libraries\n",
        "# For the sklearn library, \"pip install scikit-learn\"\n",
        "\n",
        "# Import the below libraries:\n",
        "# For working with disk data \n",
        "import os # To create reproducible file paths\n",
        "import pickle # To serialize and reserialize objects (save and load objects from disk)\n",
        "\n",
        "# For visual displays within VS Code\n",
        "from tqdm import tqdm # For the progress bar\n",
        "import warnings # To display warnings\n",
        "\n",
        "# For API access\n",
        "import earthaccess # To access satellite imagery through the NASA API\n",
        "\n",
        "# To work with different types of data and conduct data analysis\n",
        "import cartopy.crs as ccrs # To project coordinates for spatial data and mapping\n",
        "# import earthpy as et # For spatial data analysis\n",
        "import geopandas as gpd # To handle vectors/shapefiles\n",
        "import geoviews as gv # To process visualizations\n",
        "import numpy as np # To work with arrays\n",
        "import pandas as pd # To work with tables\n",
        "import re # For regular expressions; regular expression matching operations\n",
        "import rioxarray as rxr # To work with raster data\n",
        "import rioxarray.merge as rxrmerge # To merge rasters\n",
        "from shapely.geometry import Polygon # To work with polygons\n",
        "from sklearn.cluster import KMeans # For k-means clustering\n",
        "import xarray as xr # To work with data arrays\n",
        "\n",
        "# For hvPlot visualization\n",
        "import hvplot.pandas # To generate plots from Pandas dataframes\n",
        "import hvplot.xarray # To enable visualization of xarray objects\n",
        "\n",
        "# Set the GDAL parameters to avoid interruptions\n",
        "os.environ[\"GDAL_HTTP_MAX_RETRY\"] = \"5\"\n",
        "os.environ[\"GDAL_HTTP_RETRY_DELAY\"] = \"1\"\n",
        "\n",
        "# Hide non-critical warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d1daa3-a10e-472b-94ff-4ff2db336bf5",
      "metadata": {},
      "source": [
        "### Step 1b: Run the caching decorator\n",
        "\n",
        "Below you can find code for a caching **decorator** which you can use in\n",
        "your code. To use the decorator:\n",
        "\n",
        "``` python\n",
        "@cached(key, override)\n",
        "def do_something(*args, **kwargs):\n",
        "    ...\n",
        "    return item_to_cache\n",
        "```\n",
        "\n",
        "This decorator will **pickle** the results of running the\n",
        "`do_something()` function, and only run the code if the results don’t\n",
        "already exist. To override the caching, for example temporarily after\n",
        "making changes to your code, set `override=True`. Note that to use the\n",
        "caching decorator, you must write your own function to perform each\n",
        "task!\n",
        "\n",
        "You might notice that typically in these assignments, we start by creating a data_dir to store our data files. Here, our caching decorator is making the data directory for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ad0a9842",
      "metadata": {},
      "outputs": [],
      "source": [
        "# A decorator modifies or extends another function\n",
        "# Pickling the function results ensures the function only runs if the output does not exist\n",
        " \n",
        "# Make the caching decorator:\n",
        "# Define the decorator\n",
        "# Set up the rules for the caching; base name for caching = \"func_key\"\n",
        "# Set override to false to avoid reruns\n",
        "def cached(func_key, override=False):\n",
        "    # Dox strings explain what the function does\n",
        "    # Establish the parameters for the function\n",
        "    \"\"\"\n",
        "    A decorator to cache function results\n",
        "    \n",
        "    Parameters\n",
        "    ==========\n",
        "    key: str\n",
        "      File basename used to save pickled results\n",
        "    override: bool\n",
        "      When True, re-compute even if the results are already stored\n",
        "    \"\"\"\n",
        "    # Create the function that computes and saves or loads the results\n",
        "    def compute_and_cache_decorator(compute_function):\n",
        "        \"\"\"\n",
        "        Wrap the caching function\n",
        "        \n",
        "        Parameters\n",
        "        ==========\n",
        "        compute_function: function\n",
        "          The function to run and cache results\n",
        "        \"\"\"\n",
        "        # Create a function that accepts positional arguments\n",
        "        # args = Arguments that are defined by their name in the function call\n",
        "        def compute_and_cache(*args, **kwargs):\n",
        "            \"\"\"\n",
        "            Perform a computation and cache, or load cached result.\n",
        "            \n",
        "            Parameters\n",
        "            ==========\n",
        "            args\n",
        "              Positional arguments for the compute function\n",
        "            kwargs\n",
        "              Keyword arguments for the compute function\n",
        "            \"\"\"\n",
        "            # Add an identifier (\"cache_key\") from the particular function call\n",
        "            # If pass, build a single string by joining func_key with kwargs\n",
        "            # If no cache_key value is given, provide base name only\n",
        "            if 'cache_key' in kwargs:\n",
        "                key = '_'.join((func_key, kwargs['cache_key']))\n",
        "            else:\n",
        "                key = func_key\n",
        "\n",
        "            # Define a file path based on the directory structure in earthpy\n",
        "            path = os.path.join(\n",
        "                \n",
        "                # Establish the earthpy directory\n",
        "                et.io.HOME, \n",
        "                \n",
        "                # Establish the earthpy dataset\n",
        "                et.io.DATA_NAME, \n",
        "                \n",
        "                # Make a subdirectory called \"jars\"\n",
        "                'jars', \n",
        "                \n",
        "                # Use f-string (formatted string) to create a string by embedding the value of the variable \"key\" into the string \n",
        "                # Use .pickle file extension (\n",
        "                # Pickle file is a serialized python object\n",
        "                f'{key}.pickle')\n",
        "            \n",
        "            # Check if the cache exists already or if caching should be overriden\n",
        "            if not os.path.exists(path) or override:\n",
        "                \n",
        "                # Make a jars directory if needed\n",
        "                os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "                \n",
        "                # Run the compute function as the user did\n",
        "                result = compute_function(*args, **kwargs)\n",
        "                \n",
        "                # Pickle the object (save to file)\n",
        "                # Open the cache file at file name\n",
        "                with open(path, 'wb') as file:\n",
        "                    \n",
        "                    # Save the result without needing to recompute when loading it back into Python\n",
        "                    pickle.dump(result, file)\n",
        "            \n",
        "            ### If the file already exists/the cache is not being overriden:\n",
        "            else:\n",
        "               \n",
        "                # Unpickle the object (load the cached result)\n",
        "                with open(path, 'rb') as file:\n",
        "                    \n",
        "                    # Use pickle.load to unserialize the file back into a python object\n",
        "                    result = pickle.load(file)\n",
        "\n",
        "            # Return either the computed result or cached result    \n",
        "            return result\n",
        "        \n",
        "        # Return wrapper function\n",
        "        return compute_and_cache\n",
        "    \n",
        "    # Return decorator configured by func_key and override\n",
        "    return compute_and_cache_decorator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f8cf346-8ef9-4c74-8835-411b1815aac2",
      "metadata": {},
      "source": [
        "## STEP 2: Study site\n",
        "\n",
        "For this analysis, you will use a watershed from the [Water Boundary\n",
        "Dataset](https://www.usgs.gov/national-hydrography/access-national-hydrography-products),\n",
        "HU12 watersheds (WBDHU12.shp).\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "<li>Download the Water Boundary Dataset for region 8 (Mississippi)</li>\n",
        "<li>Select watershed 080902030506</li>\n",
        "<li>Generate a site map of the watershed</li>\n",
        "</ol>\n",
        "<p>Try to use the <strong>caching decorator</strong></p></div></div>\n",
        "\n",
        "We chose this watershed because it covers parts of New Orleans an is\n",
        "near the Mississippi Delta. Deltas are boundary areas between the land\n",
        "and the ocean, and as a result tend to contain a rich variety of\n",
        "different land cover and land use types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd1e3784",
      "metadata": {},
      "outputs": [],
      "source": [
        "# A level 12 watershed is the most detailed, granular way of dividing the watershed dataset\n",
        "# Assign the hydrologic unit code\n",
        "HUC_LEVEL = 12\n",
        "\n",
        "# Using the cache decorator, download, unzip, and read the shapefile:\n",
        "# Use @ to call the decorator\n",
        "@cached(f'wbd_08_hu{HUC_LEVEL}_gdf')\n",
        "\n",
        "# Make a function to read the file\n",
        "def read_wbdfile(wbd_filename, cache_key):\n",
        "    # Define the URL data is being pulled from\n",
        "    wbd_url = (\n",
        "        \"https://prd-tnm.s3.amazonaws.com/StagedProducts/Hydrography/WBD/HU2/Shape\"\n",
        "        # Insert the name of the desired file\n",
        "        f'(wbd_filename).zip'\n",
        "    )\n",
        "\n",
        "# Download the data and unzip it into the directory\n",
        "wbd_dir = et.data.get_data(url = wbd_url)\n",
        "\n",
        "# Create a path to the shapefile in the directory\n",
        "wbd_path = os.path.join(wbd_dir,\n",
        "                        'Shape',\n",
        "                        f'WBDHU{'HUC_LEVEL}.shp')\n",
        "\n",
        "# Read the shapefile as a GeoDataFrame\n",
        "wbd_gdf = gpd.read_file(wbd_path,\n",
        "                        # Use the pyogrio library\n",
        "                        engine = 'pyogrio'\n",
        "                        )\n",
        "\n",
        "# Return the GeoDataFrame for the watershed boundaries\n",
        "return wbd_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcc4f8e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "### download, unzip, and read the shapefile, and use the caching decorator to store it:\n",
        "\n",
        "### use the cached decorator to wrap the function we'll make (read_wbd_file) \n",
        "\n",
        "### define a function (read_wbd_file()) to download the watershed boundary data\n",
        "\n",
        "\n",
        "    ### define the URL to download data\n",
        "\n",
        "\n",
        "        ### insert the name of the specific file we want using an f-string\n",
        "\n",
        "\n",
        "    ### download the data and unzip it into the directory we defined earlier\n",
        "\n",
        "\n",
        "    ### make path to the shapefile in the directory\n",
        "\n",
        "\n",
        "                            ### create a subfolder\n",
        "\n",
        "\n",
        "                            ### make the shapefile name\n",
        "\n",
        "\n",
        "    ### read the shapefile as a gdf\n",
        "\n",
        "\n",
        "                            ### use pyogrio library to read the shapefile \n",
        "                            ### (better performance with large data)\n",
        "\n",
        "\n",
        "    ### return the gdf of the watershed boundaries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f04951",
      "metadata": {},
      "outputs": [],
      "source": [
        "### open the shapefile using the read_wbd_file function that we created\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffc4c16",
      "metadata": {},
      "outputs": [],
      "source": [
        "### filter the shapefile to the specific watershed we're using\n",
        "\n",
        "### define the gdf for the watershed by subsetting the gdf of the whole watershed dataset\n",
        "\n",
        "\n",
        "    ### filter the gdf to the row(s) with the watershe we want\n",
        "    ### use \"dissolve\" to merge the geometries of all the rows matching the target watershed\n",
        "\n",
        "\n",
        "### check it out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b96605f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Make a site map with satellite imagery in the background\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e779d07a-9ebd-4d84-af53-3fd1c211606c",
      "metadata": {},
      "source": [
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-response\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div></div><div class=\"callout-body-container callout-body\"><p>Write a 2-3 sentence <strong>site description</strong> (with\n",
        "citations) of this area that helps to put your analysis in context.</p></div></div>\n",
        "\n",
        "\n",
        "**YOUR SITE DESCRIPTION HERE**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9903174-b87c-4026-8564-bd3e62dbfd14",
      "metadata": {},
      "source": [
        "## STEP 3: Multispectral data\n",
        "\n",
        "### Step 3a: Search for data\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "<li>Log in to the <code>earthaccess</code> service using your Earthdata\n",
        "credentials:\n",
        "<code>python      earthaccess.login(persist=True)</code></li>\n",
        "<li>Modify the following sample code to search for granules of the\n",
        "HLSL30 product overlapping the watershed boundary from May to October\n",
        "2023 (there should be 76 granules):\n",
        "<code>python      results = earthaccess.search_data(          short_name=\"...\",          cloud_hosted=True,          bounding_box=tuple(gdf.total_bounds),          temporal=(\"...\", \"...\"),      )</code></li>\n",
        "</ol></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ec44285e",
      "metadata": {
        "highlight": true
      },
      "outputs": [],
      "source": [
        "### Log in to earthaccess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2c5840",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Search for HLS granules we want\n",
        "\n",
        "\n",
        "    ### specify which dataset and spatial resolution we want \n",
        "\n",
        "\n",
        "    ### specify that we're using cloud data\n",
        "\n",
        "\n",
        "    ### use the bounding box from our watershed boundary\n",
        "\n",
        "\n",
        "    ### set the temporal range of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2e7859c-156a-4357-a1cd-b38192090811",
      "metadata": {},
      "source": [
        "### Step 3b: Compile information about each granule\n",
        "\n",
        "I recommend building a GeoDataFrame, as this will allow you to plot the\n",
        "granules you are downloading and make sure they line up with your\n",
        "shapefile. You could also use a DataFrame, dictionary, or a custom\n",
        "object to store this information.\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "<li>For each search result:\n",
        "<ol type=\"1\">\n",
        "<li>Get the following information (HINT: look at the [‘umm’] values for\n",
        "each search result):\n",
        "<ul>\n",
        "<li>granule id (UR)</li>\n",
        "<li>datetime</li>\n",
        "<li>geometry (HINT: check out the shapely.geometry.Polygon class to\n",
        "convert points to a Polygon)</li>\n",
        "</ul></li>\n",
        "<li>Open the granule files. I recommend opening one granule at a time,\n",
        "e.g. with (<code>earthaccess.open([result]</code>).</li>\n",
        "<li>For each file (band), get the following information:\n",
        "<ul>\n",
        "<li>file handler returned from <code>earthaccess.open()</code></li>\n",
        "<li>tile id</li>\n",
        "<li>band number</li>\n",
        "</ul></li>\n",
        "</ol></li>\n",
        "<li>Compile all the information you collected into a GeoDataFrame</li>\n",
        "</ol></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "82469397",
      "metadata": {
        "highlight": true
      },
      "outputs": [],
      "source": [
        "### make a function to process all the granules from the earthaccess search\n",
        "### and extract information for each granule\n",
        "\n",
        "### define the function\n",
        "\n",
        "\n",
        "    ### make and display a progress bar\n",
        "\n",
        "\n",
        "    ### use a regular expression to extract tile_id and bank from .tif files\n",
        "\n",
        "\n",
        "    ### accumulate gdf rows from each granule\n",
        "\n",
        "\n",
        "    ### accumulate into url df\n",
        "\n",
        "\n",
        "    ### loop over granules to extract info\n",
        "\n",
        "\n",
        "        ### locate metadata (UMM = universal metadata model)\n",
        "\n",
        "\n",
        "        ### pull out unique identifier for the granule\n",
        "\n",
        "\n",
        "        ### extract date/time \n",
        "\n",
        "\n",
        "        ### extact boundary coordinates for granule\n",
        "\n",
        "\n",
        "        ### make polygon using coordinate points for granule\n",
        "\n",
        "\n",
        "        ### get url and open granule\n",
        "\n",
        "\n",
        "        ### loop through each file in the granule\n",
        "\n",
        "\n",
        "            ### use url regular expression to get url\n",
        "\n",
        "\n",
        "            ### if match is found, append data to link_rows gdf we initialized\n",
        "\n",
        "\n",
        "                    ### makes a gdf with the granule's data and geometry\n",
        "         \n",
        "\n",
        "        ### update progress bar after each granule is done\n",
        "\n",
        "\n",
        "    ### combine into a single gdf   \n",
        "\n",
        "\n",
        "    ### return the final gdf file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "394fc552-7fac-4228-a60b-beb4776718e8",
      "metadata": {},
      "source": [
        "### Step 3c: Open, crop, and mask data\n",
        "\n",
        "This will be the most resource-intensive step. I recommend caching your\n",
        "results using the `cached` decorator or by writing your own caching\n",
        "code. I also recommend testing this step with one or two dates before\n",
        "running the full computation.\n",
        "\n",
        "This code should include at least one **function** including a\n",
        "numpy-style docstring. A good place to start would be a function for\n",
        "opening a single masked raster, applying the appropriate scale\n",
        "parameter, and cropping.\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "<li>For each granule:\n",
        "<ol type=\"1\">\n",
        "<li><p>Open the Fmask band, crop, and compute a quality mask for the\n",
        "granule. You can use the following code as a starting point, making sure\n",
        "that <code>mask_bits</code> contains the quality bits you want to\n",
        "consider: ```python # Expand into a new dimension of binary bits bits =\n",
        "( np.unpackbits(da.astype(np.uint8), bitorder=‘little’)\n",
        ".reshape(da.shape + (-1,)) )</p>\n",
        "<p># Select the required bits and check if any are flagged mask =\n",
        "np.prod(bits[…, mask_bits]==0, axis=-1) ```</p></li>\n",
        "<li><p>For each band that starts with ‘B’:</p>\n",
        "<ol type=\"1\">\n",
        "<li>Open the band, crop, and apply the scale factor</li>\n",
        "<li>Name the DataArray after the band using the <code>.name</code>\n",
        "attribute</li>\n",
        "<li>Apply the cloud mask using the <code>.where()</code> method</li>\n",
        "<li>Store the DataArray in your data structure (e.g. adding a\n",
        "GeoDataFrame column with the DataArray in it. Note that you will need to\n",
        "remove the rows for unused bands)</li>\n",
        "</ol></li>\n",
        "</ol></li>\n",
        "</ol></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "68e1e0da",
      "metadata": {
        "highlight": true
      },
      "outputs": [],
      "source": [
        "### apply cached decorator to function\n",
        "\n",
        "\n",
        "\n",
        "### write function that computes reflectance data using \n",
        "### search results (df of urls) and watershed boundary\n",
        "\n",
        "\n",
        "    ### write a function to open raster from url, apply scale factor, crop, and mask data\n",
        "\n",
        "    \n",
        "\n",
        "    ### write function to apply a cloud mask\n",
        "\n",
        "\n",
        "\n",
        "        ### return the mask\n",
        "\n",
        "    \n",
        "\n",
        "    ### grab metadata\n",
        "\n",
        "\n",
        "    ### loop through each image and its metadata\n",
        "\n",
        "        \n",
        "        ### loop over each datetime/tile_id combination\n",
        "\n",
        "\n",
        "\n",
        "        ### open granule cloud cover\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        ### get cloud mask band based on url\n",
        "\n",
        "\n",
        "        ### compute cloud mask\n",
        "\n",
        "\n",
        "        ### loop through each spectral band to open, crop, and mask the band\n",
        "\n",
        "                \n",
        "\n",
        "                ### add the DataArray to the metadata df\n",
        "\n",
        "                \n",
        "                ### append the row to granule_da_rows\n",
        "\n",
        "\n",
        "            ### reassemble the metadata df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd7b8fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "### apply the function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae16533",
      "metadata": {},
      "outputs": [],
      "source": [
        "### check out the dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3f54939-7fcf-44a6-91af-57aa50b1895c",
      "metadata": {},
      "source": [
        "### Step 3d: Merge and Composite Data\n",
        "\n",
        "You will notice for this watershed that:   \n",
        "1. The raster data for each date are spread across 4 granules  \n",
        "2. Any given image is incomplete because of clouds\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "\n",
        "*   1. For each band:  \n",
        "    *   a. For each date:  \n",
        "        *   i. Merge all 4 granules  \n",
        "        *   ii. Mask any negative values created by interpolating from the nodata value of -9999 (`rioxarray`) should account for this, but doesn't appear to when merging. If you leave these values in, they will create problems later on\n",
        "    *   b. Concatenate the merged DataArrays along a new date dimension  \n",
        "    *   c. Take the mean in the date dimension to create a composite image that fills cloud gaps  \n",
        "    *   d. Add the band as a dimensions, and give the DataArray a name  \n",
        "*   2. Concatenate along the band dimension\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6d6ef620",
      "metadata": {
        "highlight": true
      },
      "outputs": [],
      "source": [
        "### apply cache decorator\n",
        "\n",
        "\n",
        "### create a function to merge and composite reflectance data from multiple granules\n",
        "### end result: single, composite reflectance image for each spectral band\n",
        "\n",
        "\n",
        "    ### initialize a list to store dfs\n",
        "    \n",
        "\n",
        "    ### initialize a list to store composites after procesing\n",
        "    \n",
        "\n",
        "    ### loop over each spectral band\n",
        "\n",
        "\n",
        "\n",
        "        ### loop over date/time of image acquisition and merge granules for each data\n",
        "\n",
        "           \n",
        "            ### mask negative values (could be no data or invalid data)\n",
        "            \n",
        "            \n",
        "\n",
        "            ### append to merged_das list we initialized\n",
        "            \n",
        "            \n",
        "        ### composite images across dates\n",
        "\n",
        "\n",
        "        \n",
        "        ### add processed and composite data array to lsit\n",
        "\n",
        "\n",
        "\n",
        "    ### concatenates composite data arrays for each band along band dimension\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e8d43be",
      "metadata": {},
      "outputs": [],
      "source": [
        "### call function to get final composite reflectance data \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d4088b9-6768-4742-90c6-f6d16254db94",
      "metadata": {},
      "source": [
        "## STEP 4: K-means clustering\n",
        "\n",
        "Cluster your data by spectral signature using the k-means algorithm.\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><ol type=\"1\">\n",
        "<li>Convert your DataArray into a <strong>tidy</strong> DataFrame of\n",
        "reflectance values (hint: check out the <code>.to_dataframe()</code> and\n",
        "<code>.unstack()</code> methods)</li>\n",
        "<li>Filter out all rows with no data (all 0s or any N/A values)</li>\n",
        "<li>Fit a k-means model. You can experiment with the number of groups to\n",
        "find what works best.</li>\n",
        "</ol></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24352b59",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Convert spectral DataArray to a tidy DataFrame\n",
        "\n",
        "### filter out rows with no data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3175495",
      "metadata": {},
      "source": [
        "Now we're reading to fit the k-means clustering model. We can run the fit and prediction functions at the same time because we don't have target data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "310d6843",
      "metadata": {},
      "outputs": [],
      "source": [
        "### initialize k-means model \n",
        "\n",
        "\n",
        "### fit model and predict\n",
        "\n",
        "\n",
        "### add the predicted values back to the model dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6417c5c9-b68e-4a7c-824a-2d1bb1aaaae5",
      "metadata": {},
      "source": [
        "## STEP 5: Plot\n",
        "\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It</div></div><div class=\"callout-body-container callout-body\"><p>Create a plot that shows the k-means clusters next to an RGB image of\n",
        "the area. You may need to brighten your RGB image by multiplying it by\n",
        "10. The code for reshaping and plotting the clusters is provided for you\n",
        "below, but you will have to create the RGB plot yourself!</p>\n",
        "<p>So, what is <code>.sortby(['x', 'y'])</code> doing for us? Try the\n",
        "code without it and find out.</p></div></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5fbde3",
      "metadata": {},
      "outputs": [],
      "source": [
        "### make data array with bands to use for rgb: red, green, and blue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b9e7ac5f",
      "metadata": {
        "highlight": true
      },
      "outputs": [],
      "source": [
        "### plot the k-means clusters\n",
        "(\n",
        "    rgb_plot\n",
        "    + \n",
        "    model_df.clusters.to_xarray().sortby(['x', 'y']).hvplot(\n",
        "        cmap=\"Colorblind\", aspect='equal') \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f764ccf-d111-4f47-bcea-8c10a7cac441",
      "metadata": {},
      "source": [
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-respond\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Reflect and Respond</div></div><div class=\"callout-body-container callout-body\"><p>Don’t forget to interpret your plot!</p></div></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4efe872d-a8ab-46bd-816f-fc5194b777a5",
      "metadata": {},
      "source": [
        "**YOUR PLOT HEADLINE AND DESCRIPTION HERE**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "earth-analytics-python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
